{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+----------+-------+\n",
      "|SepalLengh|SepalWidth|PetalLength|PetalWidth|Species|\n",
      "+----------+----------+-----------+----------+-------+\n",
      "|       5.1|       3.5|        1.4|       0.2| setosa|\n",
      "|       4.9|         3|        1.4|       0.2| setosa|\n",
      "|       4.7|       3.2|        1.3|       0.2| setosa|\n",
      "|       4.6|       3.1|        1.5|       0.2| setosa|\n",
      "|         5|       3.6|        1.4|       0.2| setosa|\n",
      "|       5.4|       3.9|        1.7|       0.4| setosa|\n",
      "|       4.6|       3.4|        1.4|       0.3| setosa|\n",
      "|         5|       3.4|        1.5|       0.2| setosa|\n",
      "|       4.4|       2.9|        1.4|       0.2| setosa|\n",
      "|       4.9|       3.1|        1.5|       0.1| setosa|\n",
      "|       5.4|       3.7|        1.5|       0.2| setosa|\n",
      "|       4.8|       3.4|        1.6|       0.2| setosa|\n",
      "|       4.8|         3|        1.4|       0.1| setosa|\n",
      "|       4.3|         3|        1.1|       0.1| setosa|\n",
      "|       5.8|         4|        1.2|       0.2| setosa|\n",
      "|       5.7|       4.4|        1.5|       0.4| setosa|\n",
      "|       5.4|       3.9|        1.3|       0.4| setosa|\n",
      "|       5.1|       3.5|        1.4|       0.3| setosa|\n",
      "|       5.7|       3.8|        1.7|       0.3| setosa|\n",
      "|       5.1|       3.8|        1.5|       0.3| setosa|\n",
      "+----------+----------+-----------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+-------------------------------+\n",
      "|   Species|avg(CAST(PetalWidth AS DOUBLE))|\n",
      "+----------+-------------------------------+\n",
      "| virginica|                          2.026|\n",
      "|versicolor|             1.3259999999999998|\n",
      "|    setosa|             0.2459999999999999|\n",
      "+----------+-------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n-----------------------------------------------------------------------------\\nHope you had some good practice !! Recommend trying out your own use cases\\n-----------------------------------------------------------------------------\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "SPARK SQL \n",
    "\n",
    "A partir de um arquivo CSV, vamos carregá-lo num Data Frame Spark SQL \n",
    "\n",
    "Nota : Spark SQL não permite que você carregue diretamente o CSV para um Data Frame. \n",
    "Vc precisa primeiro criar um RDD a partir do CSV e depois carregá-lo num Data Frame.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Inicialize o SparkSession e o SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "#Crie o Spark Session\n",
    "SpSession = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"Dataframe a partir de um RDD & SQL\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .config(\"spark.cores.max\",\"2\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"file:///c:/temp/spark-warehouse\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "#Obtenha o Spark Context do Spark Session    \n",
    "SpContext = SpSession.sparkContext\n",
    " \n",
    "irisRDD = SpContext.textFile(\"iris.csv\")\n",
    "\n",
    "#Remova o cabeçalho do arquivo CSV\n",
    "irisData = irisRDD.filter(lambda x: \"Sepal\" not in x)\n",
    "irisData.count()\n",
    "\n",
    "#Quebre as colunas\n",
    "cols = irisData.map(lambda l : l.split(\",\"))\n",
    "\n",
    "#Crie as linhas\n",
    "from pyspark.sql import Row\n",
    "irisMap = cols.map( lambda p: Row ( SepalLengh = p[0], \\\n",
    "                                   SepalWidth = p[1], \\\n",
    "                                   PetalLength = p[2], \\\n",
    "                                   PetalWidth = p[3], \\\n",
    "                                   Species = p[4] ))\n",
    "irisMap.collect()\n",
    "\n",
    "#Crie o data frame a partir do objeto Row\n",
    "irisDF = SpSession.createDataFrame(irisMap)\n",
    "irisDF.select(\"*\").show()\n",
    "\n",
    "\"\"\"\n",
    "-----------------------------------------------------------------------------\n",
    "No data frame irisDF, filtre por linhas as pétas que são maiores que 0.4 e conte-as.\n",
    "Dica: Verifique a documentação do Spark para saber como contar linhas :-)\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html\n",
    "-----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "irisDF.filter( irisDF[\"PetalWidth\"] > 0.4).count()    \n",
    "    \n",
    "\"\"\"\n",
    "-----------------------------------------------------------------------------\n",
    "#Spark SQL Tabelas Temporárias\n",
    "***********************\n",
    "\n",
    "Regitre uma tabela temporária chamada \"iris\" usando o data frame irisDF.\n",
    "Então encontre a média do tamanho das pétalas por espécie.\n",
    "\n",
    "-----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "irisDF.registerTempTable(\"iris\")\n",
    "sqlContext.sql(\"select Species,avg(PetalWidth) from iris group by Species\")\\\n",
    ".show()\n",
    "\n",
    "\"\"\"\n",
    "-----------------------------------------------------------------------------\n",
    "Espero que vocês tenham gostado !! Recomendo testar seus próprios use cases ;-)\n",
    "-----------------------------------------------------------------------------\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
